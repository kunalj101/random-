{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5188de248cf334b502219f51021fcd69acb394b"
   },
   "source": [
    "## Natural Language Processing Techniques using spaCy \n",
    "\n",
    "This notebook explains NLP techniques using python's library - spaCy\n",
    "\n",
    "### Contents \n",
    "\n",
    "1. About spaCy  \n",
    "2. Installation  \n",
    "3. Dataset Preparation for spaCy  \n",
    "4. Tokenization - Word and Sentences  \n",
    "5. Text Cleaning - Stopwords, Punctuations, Lemmatization  \n",
    "6. Dependency Parsing  \n",
    "7. Word Vector Notations  \n",
    "\n",
    "### 1. About spaCy \n",
    "\n",
    "spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python. It's designed specifically for production use and helps you build applications that process and \"understand\" large volumes of text. It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning. Following are the key features of spaCy : \n",
    "\n",
    "- Non-destructive tokenization\n",
    "- Named entity recognition\n",
    "- Support for 34+ languages\n",
    "- 13 statistical models for 8 languages\n",
    "- Pre-trained word vectors\n",
    "- Easy deep learning integration\n",
    "- Part-of-speech tagging\n",
    "- Labelled dependency parsing\n",
    "- Syntax-driven sentence segmentation\n",
    "- Built in visualizers for syntax and NER\n",
    "- Convenient string-to-hash mapping\n",
    "- Export to numpy data arrays\n",
    "- Efficient binary serialization\n",
    "- Easy model packaging and deployment\n",
    "- State-of-the-art speed\n",
    "- Robust, rigorously evaluated accuracy  \n",
    "\n",
    "With so many features inbuilt, spaCy is considered as one of the powerful NLP library. \n",
    "\n",
    "### 2. Installation \n",
    "\n",
    "To install spaCy, two steps are required, \n",
    "\n",
    "2.1 Install the spaCy source using pip command\n",
    "\n",
    "    pip install spacy\n",
    "\n",
    "2.2 Download the spacy pre-trained and annotated models  \n",
    "\n",
    "    python -m spacy download en_core_web_sm  \n",
    "    \n",
    "### 3. Dataset Preparation  \n",
    "\n",
    "We first load the required libraries and prepare the data for spaCy usage.  We will load the spacy models (which were downloaded duing the installation step) and create an object \"nlp\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff5ed9e9b8ff194c3234c2c7c15d8827108f41bd"
   },
   "source": [
    "Consider that we have a text document obtained the movie plot obtained from wikipedia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "19293f77a8fc545bde5281c2cbdccc08c3d42efa"
   },
   "outputs": [],
   "source": [
    "doc = \"\"\"Alice follows a large white rabbit down a \"Rabbit-hole\". She finds a tiny door. When she finds a bottle labeled \"Drink me\", she does, and shrinks, but not enough to pass through the door. She then eats something labeled \"Eat me\" and grows larger. She finds a fan when enables her to shrink enough to get into the \"Garden\" and try to get a \"Dog\" to play with her. She enters the \"White Rabbit's tiny House,\" but suddenly resumes her normal size. In order to get out, she has to use the \"magic fan.\"\n",
    "She enters a kitchen, in which there is a cook and a woman holding a baby. She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around. The baby then turns into a pig and squirms out of her grip. \"The Duchess's Cheshire Cat\" appears and disappears a couple of times to Alice and directs her to the Mad Hatter's \"Mad Tea-Party.\" After a while, she leaves.\n",
    "The Queen invites Alice to join the \"ROYAL PROCESSION\": a parade of marching playing cards and others headed by the White Rabbit. When Alice \"unintentionally offends the Queen\", the latter summons the \"Executioner\". Alice \"boxes the ears\", then flees when all the playing cards come for her. Then she wakes up and realizes it was all a dream.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff89553ea717c5b78afdcb5b67431803a560d801"
   },
   "source": [
    "Before using the features of spacy,  we need to convert the text document into spacy document using the \"nlp\" object created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "f5f4a400882611bccdf41156274559356431a391"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice follows a large white rabbit down a \"Rabbit-hole\". She finds a tiny door. When she finds a bottle labeled \"Drink me\", she does, and shrinks, but not enough to pass through the door. She then eats something labeled \"Eat me\" and grows larger. She finds a fan when enables her to shrink enough to get into the \"Garden\" and try to get a \"Dog\" to play with her. She enters the \"White Rabbit's tiny House,\" but suddenly resumes her normal size. In order to get out, she has to use the \"magic fan.\"\n",
       "She enters a kitchen, in which there is a cook and a woman holding a baby. She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around. The baby then turns into a pig and squirms out of her grip. \"The Duchess's Cheshire Cat\" appears and disappears a couple of times to Alice and directs her to the Mad Hatter's \"Mad Tea-Party.\" After a while, she leaves.\n",
       "The Queen invites Alice to join the \"ROYAL PROCESSION\": a parade of marching playing cards and others headed by the White Rabbit. When Alice \"unintentionally offends the Queen\", the latter summons the \"Executioner\". Alice \"boxes the ears\", then flees when all the playing cards come for her. Then she wakes up and realizes it was all a dream."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_doc = nlp(doc)\n",
    "spacy_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef17605014a2108c7923b0147520c51c2856a5cf"
   },
   "source": [
    "### 4. Tokenization \n",
    "\n",
    "First, we will see how can we perform tokenization at word level and sentence level using spacy. \n",
    "\n",
    "**Word Level Tokenization** : To obtain word tokens, we just need to access the spacy document as list, all the tokens will be obtained. This is because when we converted the document into spacy document, this step was already performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "22c035d9c6f731f6ec0976d4a1e81852d2ae8fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice, follows, a, large, white, rabbit, down, a, \", Rabbit, -, hole, \", ., She, finds, a, tiny, door, ., When, she, finds, a, bottle, labeled, \", Drink, me, \", ,, she, does, ,, and, shrinks, ,, but, not, enough, to, pass, through, the, door, ., She, then, eats, something, labeled, \", Eat, me, \", and, grows, larger, ., She, finds, a, fan, when, enables, her, to, shrink, enough, to, get, into, the, \", Garden, \", and, try, to, get, a, \", Dog, \", to, play, with, her, ., She, enters, the, \", White, Rabbit, 's, tiny, House, ,, \", but, suddenly, resumes, her, normal, size, ., In, order, to, get, out, ,, she, has, to, use, the, \", magic, fan, ., \", \n",
      ", She, enters, a, kitchen, ,, in, which, there, is, a, cook, and, a, woman, holding, a, baby, ., She, persuades, the, woman, to, give, her, the, child, and, takes, the, infant, outside, after, the, cook, starts, throwing, things, around, ., The, baby, then, turns, into, a, pig, and, squirms, out, of, her, grip, ., \", The, Duchess, 's, Cheshire, Cat, \", appears, and, disappears, a, couple, of, times, to, Alice, and, directs, her, to, the, Mad, Hatter, 's, \", Mad, Tea, -, Party, ., \", After, a, while, ,, she, leaves, ., \n",
      ", The, Queen, invites, Alice, to, join, the, \", ROYAL, PROCESSION, \", :, a, parade, of, marching, playing, cards, and, others, headed, by, the, White, Rabbit, ., When, Alice, \", unintentionally, offends, the, Queen, \", ,, the, latter, summons, the, \", Executioner, \", ., Alice, \", boxes, the, ears, \", ,, then, flees, when, all, the, playing, cards, come, for, her, ., Then, she, wakes, up, and, realizes, it, was, all, a, dream, .]\n"
     ]
    }
   ],
   "source": [
    "tokens = list(spacy_doc)\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1424a33c7c1c1a18a57d7b5f9ad787ca753b620d"
   },
   "source": [
    "Similarly, for **sentence level tokenization**, we can acess the sentences using following syntax. It will give a generator object. \n",
    "\n",
    "    spacy_doc.sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "2d7d35801f121650c52605acce1872698760c0e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Alice follows a large white rabbit down a \"Rabbit-hole\".\n",
      "1 She finds a tiny door.\n",
      "2 When she finds a bottle labeled \"Drink me\", she does, and shrinks, but not enough to pass through the door.\n",
      "3 She then eats something labeled \"Eat me\" and grows larger.\n",
      "4 She finds a fan when enables her to shrink enough to get into the \"Garden\" and try to get a \"Dog\" to play with her.\n",
      "5 She enters the \"White Rabbit's tiny House,\" but suddenly resumes her normal size.\n",
      "6 In order to get out, she has to use the \"magic fan.\"\n",
      "\n",
      "7 She enters a kitchen, in which there is a cook and a woman holding a baby.\n",
      "8 She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around.\n",
      "9 The baby then turns into a pig and squirms out of her grip. \"\n",
      "10 The Duchess's Cheshire Cat\" appears and disappears a couple of times to Alice and directs her to the Mad Hatter's \"Mad Tea-Party.\"\n",
      "11 After a while, she leaves.\n",
      "\n",
      "12 The Queen invites Alice to join the \"ROYAL PROCESSION\": a parade of marching playing cards and others headed by the White Rabbit.\n",
      "13 When Alice \"unintentionally offends the Queen\", the latter summons the \"Executioner\".\n",
      "14 Alice \"boxes the ears\", then flees when all the playing cards come for her.\n",
      "15 Then she wakes up and realizes it was all a dream.\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in enumerate(spacy_doc.sents):\n",
    "    print (index, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "02a87ebb83ab84caf5e09602e0e29a7c05c58070"
   },
   "source": [
    "### 5. Text Cleaning \n",
    "\n",
    "In this section, we will see how can we access different properties of tokens produced in spacy object that can be used to remove noise in the text. Different properties of spacy tokens can be viewed using following syntax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "cc70b06a5a5a4d073620628e65a9112e9a0f171c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', 'ancestors', 'check_flag', 'children', 'cluster', 'conjuncts', 'dep', 'dep_', 'doc', 'ent_id', 'ent_id_', 'ent_iob', 'ent_iob_', 'ent_type', 'ent_type_', 'get_extension', 'has_extension', 'has_vector', 'head', 'i', 'idx', 'is_alpha', 'is_ancestor', 'is_ascii', 'is_bracket', 'is_currency', 'is_digit', 'is_left_punct', 'is_lower', 'is_oov', 'is_punct', 'is_quote', 'is_right_punct', 'is_sent_start', 'is_space', 'is_stop', 'is_title', 'is_upper', 'lang', 'lang_', 'left_edge', 'lefts', 'lemma', 'lemma_', 'lex_id', 'like_email', 'like_num', 'like_url', 'lower', 'lower_', 'n_lefts', 'n_rights', 'nbor', 'norm', 'norm_', 'orth', 'orth_', 'pos', 'pos_', 'prefix', 'prefix_', 'prob', 'rank', 'remove_extension', 'right_edge', 'rights', 'sent', 'sent_start', 'sentiment', 'set_extension', 'shape', 'shape_', 'similarity', 'string', 'subtree', 'suffix', 'suffix_', 'tag', 'tag_', 'text', 'text_with_ws', 'vector', 'vector_norm', 'vocab', 'whitespace_']\n"
     ]
    }
   ],
   "source": [
    "first_word = tokens[0]\n",
    "print (dir(first_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f24e005b6541dee7fd43b3727c5068ec5347d344"
   },
   "source": [
    "We can see that there are many properties of every token. Let's view some of these properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "5fd15d589c534599763615dd4208c15efc4f9360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_bracket:  False\n",
      "like_num:  False\n",
      "right_edge:  Alice\n",
      "sentiment:  0.0\n",
      "dep_:  nsubj\n"
     ]
    }
   ],
   "source": [
    "print (\"is_bracket: \", first_word.is_bracket)\n",
    "print (\"like_num: \", first_word.like_num)\n",
    "print (\"right_edge: \", first_word.right_edge)\n",
    "print (\"sentiment: \", first_word.sentiment)\n",
    "print (\"dep_: \", first_word.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c28c85d904580c205f00022f83e48e520fb4c06b"
   },
   "source": [
    "Using these properties, we can infact clean the text data. For example, following code cell shows how to remove the tokens which are punctuations and stopwords, and lemmatize the remaining ones. \n",
    "\n",
    "#### Removal of Punctionation \n",
    "\n",
    "property : is_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "7545e863080f3dac4d617869d7144faac89aacbb"
   },
   "outputs": [],
   "source": [
    "tokens = [t for t in tokens if (t.is_punct == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice, follows, large, white, rabbit, Rabbit, hole, She, finds, tiny, door, When, finds, bottle, labeled, Drink, shrinks, pass, door, She, eats, labeled, Eat, grows, larger, She, finds, fan, enables, shrink, Garden, try, Dog, play, She, enters, White, Rabbit, 's, tiny, House, suddenly, resumes, normal, size, In, order, use, magic, fan, \n",
      ", She, enters, kitchen, cook, woman, holding, baby, She, persuades, woman, child, takes, infant, outside, cook, starts, throwing, things, The, baby, turns, pig, squirms, grip, The, Duchess, 's, Cheshire, Cat, appears, disappears, couple, times, Alice, directs, Mad, Hatter, 's, Mad, Tea, Party, After, leaves, \n",
      ", The, Queen, invites, Alice, join, ROYAL, PROCESSION, parade, marching, playing, cards, headed, White, Rabbit, When, Alice, unintentionally, offends, Queen, summons, Executioner, Alice, boxes, ears, flees, playing, cards, come, Then, wakes, realizes, dream]\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdb6f81eb56374bf3e19b49ad1fa1c00efd14646"
   },
   "source": [
    "#### Removal of Stopwords \n",
    "\n",
    "property : is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "d1534ad9d037f87e93e8b14792d029658b3b60b8"
   },
   "outputs": [],
   "source": [
    "tokens = [t for t in tokens if (t.is_stop == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice, follows, large, white, rabbit, Rabbit, hole, She, finds, tiny, door, When, finds, bottle, labeled, Drink, shrinks, pass, door, She, eats, labeled, Eat, grows, larger, She, finds, fan, enables, shrink, Garden, try, Dog, play, She, enters, White, Rabbit, 's, tiny, House, suddenly, resumes, normal, size, In, order, use, magic, fan, \n",
      ", She, enters, kitchen, cook, woman, holding, baby, She, persuades, woman, child, takes, infant, outside, cook, starts, throwing, things, The, baby, turns, pig, squirms, grip, The, Duchess, 's, Cheshire, Cat, appears, disappears, couple, times, Alice, directs, Mad, Hatter, 's, Mad, Tea, Party, After, leaves, \n",
      ", The, Queen, invites, Alice, join, ROYAL, PROCESSION, parade, marching, playing, cards, headed, White, Rabbit, When, Alice, unintentionally, offends, Queen, summons, Executioner, Alice, boxes, ears, flees, playing, cards, come, Then, wakes, realizes, dream]\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b049b6af808a51265e6572be13f0f9cd596dce1"
   },
   "source": [
    "#### Token lemmatization\n",
    "\n",
    "property : lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "15879607c719a9d64937e982b6f7990d7d4fa858"
   },
   "outputs": [],
   "source": [
    "lemmatized_words = [token.lemma_ for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', 'follow', 'large', 'white', 'rabbit', 'rabbit', 'hole', '-PRON-', 'find', 'tiny', 'door', 'when', 'find', 'bottle', 'label', 'drink', 'shrink', 'pass', 'door', '-PRON-', 'eat', 'label', 'eat', 'grow', 'large', '-PRON-', 'find', 'fan', 'enable', 'shrink', 'garden', 'try', 'dog', 'play', '-PRON-', 'enter', 'white', 'rabbit', \"'s\", 'tiny', 'house', 'suddenly', 'resume', 'normal', 'size', 'in', 'order', 'use', 'magic', 'fan', '\\n', '-PRON-', 'enter', 'kitchen', 'cook', 'woman', 'hold', 'baby', '-PRON-', 'persuade', 'woman', 'child', 'take', 'infant', 'outside', 'cook', 'start', 'throw', 'thing', 'the', 'baby', 'turn', 'pig', 'squirm', 'grip', 'the', 'duchess', \"'s\", 'cheshire', 'cat', 'appear', 'disappear', 'couple', 'time', 'alice', 'direct', 'mad', 'hatter', \"'s\", 'mad', 'tea', 'party', 'after', 'leave', '\\n', 'the', 'queen', 'invite', 'alice', 'join', 'royal', 'procession', 'parade', 'march', 'playing', 'card', 'head', 'white', 'rabbit', 'when', 'alice', 'unintentionally', 'offend', 'queen', 'summon', 'executioner', 'alice', 'box', 'ear', 'flee', 'playing', 'card', 'come', 'then', 'wake', 'realize', 'dream']\n"
     ]
    }
   ],
   "source": [
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33171ba64381dff231882d20a1107c27bdd63497"
   },
   "source": [
    "Finally, we join these lemmatized words to produce a cleaned document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "3995204a51a06a3c4239179cd76787c8c648f849"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"alice follow large white rabbit rabbit hole -PRON- find tiny door when find bottle label drink shrink pass door -PRON- eat label eat grow large -PRON- find fan enable shrink garden try dog play -PRON- enter white rabbit 's tiny house suddenly resume normal size in order use magic fan \\n -PRON- enter kitchen cook woman hold baby -PRON- persuade woman child take infant outside cook start throw thing the baby turn pig squirm grip the duchess 's cheshire cat appear disappear couple time alice direct mad hatter 's mad tea party after leave \\n the queen invite alice join royal procession parade march playing card head white rabbit when alice unintentionally offend queen summon executioner alice box ear flee playing card come then wake realize dream\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_doc = \" \".join(lemmatized_words)\n",
    "cleaned_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2d2e547ada58362e5e1f8c48c1d69cb2270c952"
   },
   "source": [
    "### 6. Dependency Parsing\n",
    "\n",
    "Finally, we look at how can we obtain dependecy grammar relations in the sentences. We will use \"dep\" property for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "835e06d375135c5f01d3f155e601373565bb02e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  Alice ( nsubj )\n",
      "Token:  follows ( ROOT )\n",
      "Token:  a ( det )\n",
      "Token:  large ( amod )\n",
      "Token:  white ( amod )\n",
      "Token:  rabbit ( dobj )\n",
      "Token:  down ( prep )\n",
      "Token:  a ( det )\n",
      "Token:  \" ( punct )\n",
      "Token:  Rabbit ( compound )\n",
      "Token:  - ( punct )\n",
      "Token:  hole ( pobj )\n",
      "Token:  \" ( punct )\n",
      "Token:  . ( punct )\n"
     ]
    }
   ],
   "source": [
    "for token in list(spacy_doc.sents)[0]:\n",
    "    print (\"Token: \", token.text, \"(\", token.dep_, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1a5bbf37bc19db79d3707f9abc261a940f22696"
   },
   "source": [
    "Let's visualize the grammar tree as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "9e529e72dbfb041ed8c737d0c8ef22676f60fd70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1550\" height=\"512.0\" style=\"max-width: none; height: 512.0px; color: white; background: #09a3d5; font-family: Trebuchet MS\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Alice</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">follows</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">large</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">white</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">rabbit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">down</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">a &quot;</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">Rabbit-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">hole&quot;.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M62,377.0 62,352.0 188.0,352.0 188.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,379.0 L58,371.0 66,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M362,377.0 362,302.0 794.0,302.0 794.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M362,379.0 L358,371.0 366,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M512,377.0 512,327.0 791.0,327.0 791.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M512,379.0 L508,371.0 516,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M662,377.0 662,352.0 788.0,352.0 788.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M662,379.0 L658,371.0 666,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M212,377.0 212,277.0 797.0,277.0 797.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M797.0,379.0 L801.0,371.0 793.0,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M212,377.0 212,252.0 950.0,252.0 950.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,379.0 L954.0,371.0 946.0,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M1112,377.0 1112,327.0 1391.0,327.0 1391.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1112,379.0 L1108,371.0 1116,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M1262,377.0 1262,352.0 1388.0,352.0 1388.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1262,379.0 L1258,371.0 1266,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M962,377.0 962,302.0 1394.0,302.0 1394.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1394.0,379.0 L1398.0,371.0 1390.0,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options = {'compact': True, 'bg': '#09a3d5', 'color': 'white', 'font': 'Trebuchet MS'}\n",
    "spacy.displacy.render(list(spacy_doc.sents)[0], jupyter=True, style='dep', options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08bd117a26825dcd76464d6cd7cf90d5f4218878"
   },
   "source": [
    "### 7. Vector Notations \n",
    "\n",
    "Apart from these features spaCy also provides word vector notations of every token which can be used in machine learning tasks. \n",
    "\n",
    "Let's say we have a token = \"King\", we can obtain its vector notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "5a0b55e199aa992a947408011d5aac859efe6b27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.36204290e-02, -8.18971217e-01,  3.63455534e+00,  2.16690850e+00,\n",
       "       -1.67162549e+00,  3.46462321e+00, -3.57993436e+00, -1.72307217e+00,\n",
       "        1.73067009e+00,  2.10129118e+00,  3.35882425e+00, -7.59031653e-01,\n",
       "        9.56273794e-01,  4.69955862e-01,  7.83543766e-01,  1.28527331e+00,\n",
       "       -1.40461540e+00, -3.32550907e+00, -6.67833388e-01,  4.96354163e-01,\n",
       "        1.80125880e+00,  2.13869023e+00,  2.20085919e-01,  5.51033437e-01,\n",
       "       -7.88275957e-01,  8.79898816e-02, -4.55687761e-01, -8.05754423e-01,\n",
       "       -1.39082909e+00, -3.24309063e+00, -3.16947341e+00, -1.39425468e+00,\n",
       "       -1.37564540e+00, -1.00767970e+00,  9.31471586e-01, -1.80383682e+00,\n",
       "       -1.09933567e+00, -1.16600096e-01,  1.15281534e+00, -1.09492981e+00,\n",
       "       -1.68272817e+00, -2.15604365e-01,  2.76870441e+00, -1.39123464e+00,\n",
       "       -3.18668890e+00, -9.00622010e-01,  1.87046260e-01, -1.16345692e+00,\n",
       "        1.70678830e+00, -1.14646721e+00,  8.06652427e-01, -2.93603659e+00,\n",
       "       -5.94434977e-01,  4.82532382e-03,  1.29977298e+00, -7.49819398e-01,\n",
       "        2.51717949e+00,  6.84893608e-01,  1.50650918e+00,  2.36989230e-01,\n",
       "       -2.88870335e+00,  2.25257659e+00, -3.84914494e+00,  1.25159478e+00,\n",
       "       -1.30558640e-01,  1.30018783e+00, -5.40122807e-01, -3.01346278e+00,\n",
       "        4.53247166e+00,  2.18475056e+00, -1.44977450e+00, -1.77295256e+00,\n",
       "        2.06164789e+00,  2.59317708e+00, -1.66144681e+00,  2.51855278e+00,\n",
       "        1.01124024e+00,  1.06093514e+00, -1.29394615e+00, -1.20858967e+00,\n",
       "       -4.74221563e+00, -1.27879214e+00, -8.83996010e-01, -1.81508839e+00,\n",
       "        3.38588059e-01,  5.32065451e-01, -8.54224682e-01, -3.80813599e-01,\n",
       "       -1.81013501e+00,  1.44999552e+00, -3.53064585e+00,  4.05260563e+00,\n",
       "       -2.72159147e+00,  1.41244853e+00, -5.09188414e-01,  3.77614903e+00,\n",
       "       -2.88020658e+00, -6.71420038e-01,  3.77341413e+00, -1.05814254e+00,\n",
       "       -1.09716153e+00,  3.72505426e+00,  2.09358454e+00, -2.28225541e+00,\n",
       "        1.83806384e+00,  1.36213732e+00,  3.28416491e+00, -1.88360012e+00,\n",
       "       -2.54660535e+00, -9.99541581e-01,  1.13901770e+00, -1.20990181e+00,\n",
       "        6.52715683e-01, -2.78207493e+00,  1.32799840e+00,  8.02118659e-01,\n",
       "       -6.32757187e-01,  2.56893635e-01,  1.73996568e+00,  7.15930879e-01,\n",
       "        1.87716115e+00,  3.86574030e-01,  2.68294358e+00,  3.65926075e+00,\n",
       "       -4.56700087e-01,  3.38449240e-01,  2.95076561e+00, -3.58714163e-01,\n",
       "       -6.48129225e-01,  1.21493697e-01,  1.01344094e-01,  8.58253017e-02,\n",
       "       -3.36185604e-01,  1.41238779e-01, -8.46380472e-01,  7.86105394e-01,\n",
       "        2.24096522e-01,  8.61746222e-02,  4.97830451e-01, -1.28819466e-01,\n",
       "       -1.22818768e-01, -7.51433372e-02, -2.94258416e-01, -2.13864014e-01,\n",
       "        2.35493258e-02,  5.22624016e-01,  1.99822098e-01, -3.71734858e-01,\n",
       "       -8.45552385e-02,  8.46459508e-01,  1.40024304e-01, -1.83224827e-02,\n",
       "        7.38978386e-03, -5.76578259e-01,  2.79772282e-03, -5.18503606e-01,\n",
       "       -8.87089521e-02, -3.45058560e-01, -6.08844101e-01,  3.69032294e-01,\n",
       "       -5.79922080e-01,  1.04628503e-03, -9.68987346e-02,  1.35559216e-01,\n",
       "        5.56392491e-01,  3.43127340e-01,  6.34472370e-01,  2.31750563e-01,\n",
       "       -3.49255741e-01,  1.43101662e-02, -4.95434999e-01, -3.77096891e-01,\n",
       "       -1.77628756e-01, -8.99572372e-02, -1.54051572e-01, -6.30802035e-01,\n",
       "       -2.89627850e-01,  4.76614505e-01, -1.16073787e-02, -2.66920894e-01,\n",
       "        6.49742186e-02, -2.28899613e-01,  7.04843700e-02, -6.24139607e-02,\n",
       "        8.45329702e-01,  1.06101930e-02,  1.03377926e+00,  8.67212787e-02,\n",
       "        2.07885608e-01,  1.71693981e-01,  8.07771504e-01, -1.63320765e-01,\n",
       "        1.75151378e-02,  2.38606855e-02,  8.90173540e-02,  3.62389892e-01,\n",
       "       -4.01611254e-03, -1.67573273e-01, -7.21773803e-02, -1.92435086e-01,\n",
       "        7.01278567e-01,  1.13653451e-01, -1.67893171e-01,  9.35621187e-02,\n",
       "        9.51665819e-01,  5.87377131e-01,  1.19881630e-01, -1.24269515e-01,\n",
       "        5.23148060e-01, -6.20964110e-01, -8.23733985e-01, -3.56144607e-01,\n",
       "        3.78195852e-01,  1.75166786e-01, -1.07036948e+00, -3.10167491e-01,\n",
       "       -7.56491661e-01, -3.34872872e-01,  6.19666696e-01, -2.37638637e-01,\n",
       "       -3.73104572e-01,  1.69980913e-01,  3.68166387e-01, -3.67440194e-01,\n",
       "       -6.90715432e-01, -6.74131274e-01, -1.09906659e-01, -6.87495917e-02,\n",
       "       -1.19220972e-01,  9.24806118e-01, -4.48621750e-01,  1.08081353e+00,\n",
       "        3.71627301e-01,  8.41480717e-02, -8.18671823e-01,  7.97054052e-01,\n",
       "       -5.22307098e-01,  1.31810486e-01, -2.25832790e-01, -3.82717222e-01,\n",
       "        6.17726684e-01, -1.74377456e-01,  2.62505352e-01, -3.89007986e-01,\n",
       "       -5.60180008e-01,  1.16280288e-01, -5.70898414e-01,  2.58208185e-01,\n",
       "       -5.03693342e-01, -5.22964001e-01, -3.37971240e-01,  8.47196817e-01,\n",
       "       -2.75847137e-01,  3.87070656e-01,  7.66755044e-01,  6.43411398e-01,\n",
       "       -5.89586794e-01, -4.02825832e-01,  5.66967070e-01,  2.15358749e-01,\n",
       "       -5.76746836e-02, -8.63910615e-02,  2.84459591e-01, -1.95754871e-01,\n",
       "        3.90181690e-03, -8.79245400e-02,  3.72945756e-01, -6.79531395e-01,\n",
       "       -4.10377055e-01, -4.52059627e-01, -1.90871835e-01,  5.42393506e-01,\n",
       "       -1.63626581e-01,  2.04784274e-02, -8.22854638e-01, -4.57965791e-01,\n",
       "       -6.07594728e-01, -3.05438876e-01,  2.55517289e-02, -5.26460469e-01,\n",
       "       -6.96332991e-01, -3.84592175e-01, -8.82741928e-01,  4.32028383e-01,\n",
       "       -7.38563612e-02, -4.08435494e-01, -4.33339775e-01, -2.35756367e-01,\n",
       "        4.42523003e-01,  1.70808628e-01, -1.69271991e-01, -6.06400609e-01,\n",
       "        6.43143952e-02,  7.43733466e-01,  6.34364069e-01, -1.77351952e-01,\n",
       "        3.03767532e-01,  5.72189450e-01,  4.29300189e-01, -8.26412320e-01,\n",
       "       -9.88241956e-02, -1.61986858e-01,  4.60772216e-01, -7.81567156e-01,\n",
       "        4.15814877e-01, -1.08388282e-01,  5.32365680e-01, -9.82908487e-01,\n",
       "        4.39542979e-01, -5.98528981e-03, -1.33766189e-01,  1.51706707e+00,\n",
       "       -7.06534803e-01,  2.66370952e-01,  5.04644513e-01,  6.33882284e-01,\n",
       "        2.89248735e-01,  1.21328197e-01,  5.61184943e-01,  4.92432564e-02,\n",
       "        1.71638727e-01,  2.05815911e-01, -5.45424461e-01,  9.70120966e-01,\n",
       "       -2.82463014e-01,  7.34191895e-01, -1.06664270e-01,  4.33283523e-02,\n",
       "       -4.02559221e-01,  1.24319375e-01,  7.52038956e-01,  8.83222759e-01,\n",
       "        3.81875634e-01,  8.67608190e-01, -3.78508508e-01,  1.93645462e-01,\n",
       "       -7.15603292e-01, -2.59227484e-01, -3.48208919e-02,  5.31112552e-01,\n",
       "       -1.22695848e-01,  3.07454169e-01, -3.57093006e-01, -2.06512511e-02,\n",
       "        2.16738492e-01, -1.83765262e-01,  1.90667182e-01,  3.32689196e-01,\n",
       "        3.37262154e-01,  1.06970988e-01,  3.64145130e-01, -2.31417954e-01,\n",
       "       -5.32120943e-01,  6.61590636e-01, -2.29570314e-01,  2.10927024e-01,\n",
       "       -2.64441371e-01, -2.05070704e-01, -7.60098636e-01, -8.67586136e-01,\n",
       "       -7.80944109e-01,  5.92315018e-01, -7.29404762e-02,  2.09306985e-01,\n",
       "       -5.98913014e-01, -3.28421682e-01,  5.45626692e-02, -2.16613203e-01,\n",
       "        4.27097321e-01,  4.52405751e-01, -3.37576956e-01,  6.65850282e-01,\n",
       "        1.86659947e-01, -1.56861335e-01,  1.09135735e+00,  6.80505276e-01,\n",
       "       -1.05907887e-01, -2.61337101e-01,  1.42049849e-01, -3.01596940e-01,\n",
       "       -5.48672318e-01, -1.81300402e-01,  1.86390162e-01, -3.05498242e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = nlp(u'king')\n",
    "token.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "703bc546bae77b987175f3178947a9b083116c46"
   },
   "source": [
    "Let's also print the vector of the token = \"man\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "976089889ff60602b5c78ee74e83f9e0509b3a9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.14936864e+00,  2.05398750e+00,  3.04558372e+00,  1.02784121e+00,\n",
       "       -6.93390787e-01,  1.93840325e+00, -3.38449144e+00, -1.46062493e+00,\n",
       "        8.66490662e-01,  2.06204748e+00,  1.73931348e+00, -1.37765062e+00,\n",
       "       -6.98180556e-01, -1.40720224e+00,  3.26218963e-01,  1.21163011e-01,\n",
       "        1.34245634e-01, -9.06486392e-01, -4.54380572e-01,  1.91038847e+00,\n",
       "        1.84738982e+00,  2.62389016e+00,  2.65023947e-01,  6.50504053e-01,\n",
       "       -1.11452436e+00,  9.24800456e-01, -2.47930914e-01,  3.19516957e-01,\n",
       "        1.31793320e-01, -1.47506547e+00, -1.08989477e-02, -1.06771803e+00,\n",
       "        9.76389349e-01, -3.80290419e-01,  7.58833528e-01, -6.24958634e-01,\n",
       "       -8.05267990e-01,  3.25525570e+00,  1.28473425e+00,  5.32162070e-01,\n",
       "       -2.33017325e+00,  9.98796701e-01,  1.82712984e+00, -1.37855679e-01,\n",
       "       -3.35902619e+00, -1.20148849e+00, -1.63074863e+00, -3.01429987e+00,\n",
       "        4.44018841e+00, -3.28304195e+00,  8.05817604e-01, -2.11897516e+00,\n",
       "        8.20012450e-01,  3.19708884e-02, -1.34611237e+00,  4.13680732e-01,\n",
       "        3.57538223e+00, -1.16323340e+00, -3.06360483e-01,  4.69807982e-01,\n",
       "       -2.10338640e+00, -1.12857044e+00, -3.01801324e+00,  1.54522133e+00,\n",
       "       -1.01865923e+00,  4.00264531e-01, -1.12721920e-02, -1.50166035e+00,\n",
       "        3.11996174e+00,  6.61824107e-01, -2.84986377e+00, -5.79370797e-01,\n",
       "        3.22822809e-01,  1.05026722e+00, -3.00702286e+00, -1.87763309e+00,\n",
       "        1.47807527e+00,  1.42329836e+00, -6.84975028e-01, -1.90530300e-01,\n",
       "       -4.79580545e+00, -3.10195470e+00, -3.02487183e+00, -7.22046852e-01,\n",
       "       -1.15278053e+00,  1.85774171e+00, -2.15699887e+00, -2.44907427e+00,\n",
       "       -2.22751307e+00, -1.84340823e+00, -4.19620848e+00,  6.60465384e+00,\n",
       "       -2.84388304e+00,  9.90790844e-01, -5.01644850e-01,  4.36247826e+00,\n",
       "       -3.14032674e+00,  5.63748240e-01,  2.13808155e+00, -9.10863757e-01,\n",
       "        2.08879709e-02,  3.81275463e+00,  1.16021365e-01, -2.93946981e+00,\n",
       "        2.12059999e+00,  1.51169086e+00,  2.18996859e+00, -3.09312606e+00,\n",
       "       -1.24175715e+00,  1.60558569e+00,  8.00220013e-01, -1.37212479e+00,\n",
       "        5.76481700e-01, -2.58378553e+00,  2.25127792e+00,  2.98779917e+00,\n",
       "       -1.27935076e+00, -7.60142326e-01,  1.70797968e+00, -5.87987185e-01,\n",
       "        4.44794989e+00,  1.81658173e+00,  1.49297690e+00,  1.53552234e+00,\n",
       "        3.51855159e-02,  1.69594777e+00,  5.60222673e+00,  2.60595918e-01,\n",
       "       -6.11629248e-01, -3.72877359e-01,  1.98236108e-01,  2.23602891e-01,\n",
       "       -3.36359411e-01,  5.39815605e-01, -6.74492419e-01,  9.15487647e-01,\n",
       "       -1.71635002e-01,  1.35051936e-01,  7.74602711e-01,  3.53193164e-01,\n",
       "       -1.59769803e-01, -3.00221056e-01, -3.13721210e-01,  9.78252292e-02,\n",
       "       -3.71059090e-01,  6.24629140e-01,  3.89070719e-01, -1.46220610e-01,\n",
       "       -3.03268492e-01,  1.14523128e-01, -6.66873977e-02, -3.04885358e-02,\n",
       "       -1.99569196e-01, -5.38708448e-01, -1.05705410e-02, -3.51037651e-01,\n",
       "       -1.89763039e-01, -6.54046476e-01, -2.38172129e-01, -2.12893397e-01,\n",
       "       -2.41570532e-01, -1.26724929e-01, -6.34259582e-02, -1.87768131e-01,\n",
       "        7.47192621e-01,  2.29953796e-01, -7.35918880e-02,  2.77737200e-01,\n",
       "       -6.12884820e-01,  2.22693920e-01,  1.79826215e-01, -3.89633477e-01,\n",
       "       -3.89921665e-02,  3.46775711e-01, -2.70336643e-02, -3.67593884e-01,\n",
       "       -3.02976698e-01,  2.12969854e-02,  5.09830415e-02, -2.93935120e-01,\n",
       "       -2.20650136e-02, -6.28715634e-01,  1.46890998e-01,  4.83004987e-01,\n",
       "        5.18416047e-01, -1.60159230e-01,  8.99483502e-01,  1.20297529e-01,\n",
       "        6.17548227e-01,  2.06888467e-01,  6.04627371e-01,  4.91252989e-02,\n",
       "       -1.70081139e-01,  3.06065917e-01, -6.58830777e-02,  1.30690783e-02,\n",
       "       -9.38501731e-02, -1.81739271e-01, -4.62568134e-01, -4.41359103e-01,\n",
       "        6.66966140e-01, -2.81039715e-01, -3.53903860e-01,  1.67125344e-01,\n",
       "        6.37601733e-01,  1.51047394e-01,  1.12040997e-01,  2.20179111e-01,\n",
       "        2.97453523e-01, -3.95601451e-01, -1.00795603e+00,  7.69690573e-02,\n",
       "        2.00184733e-01,  4.20916855e-01, -1.10605824e+00, -3.80314231e-01,\n",
       "       -4.78580475e-01, -6.28799200e-03,  2.99299330e-01, -1.70606241e-01,\n",
       "       -4.24873888e-01,  8.29199851e-02,  1.96779996e-01, -1.44017160e-01,\n",
       "       -3.60628009e-01, -4.92429376e-01,  9.20040905e-02, -4.10771281e-01,\n",
       "       -2.65022129e-01,  1.03208077e+00, -5.79534173e-01,  1.18836010e+00,\n",
       "        4.02728617e-01, -6.97104633e-03, -6.46014750e-01,  3.19123209e-01,\n",
       "       -5.46311855e-01,  1.78679645e-01, -5.75606525e-02, -3.91826361e-01,\n",
       "        1.60344884e-01, -4.23284709e-01,  4.99030501e-01, -6.39975429e-01,\n",
       "        2.77599022e-02, -1.23919934e-01, -1.36114195e-01,  5.50831556e-01,\n",
       "       -1.88982055e-01, -5.87557435e-01, -1.68744862e-01,  5.51306903e-01,\n",
       "       -3.54658276e-01,  4.50495571e-01,  2.87305236e-01,  3.43646020e-01,\n",
       "       -4.80261445e-01, -2.02185452e-01,  4.45612878e-01,  8.05344284e-02,\n",
       "       -3.18718553e-01, -2.87405729e-01, -3.78421247e-01,  4.57637236e-02,\n",
       "        1.54512227e-01, -4.06508148e-02, -1.30366176e-01, -2.54718274e-01,\n",
       "        4.14907932e-03, -3.12016100e-01, -3.91340345e-01,  7.42963731e-01,\n",
       "       -2.81019241e-01, -1.76541299e-01, -4.74499047e-01, -3.15058768e-01,\n",
       "        1.81552351e-01, -4.85381335e-01,  1.26785707e+00,  2.55188942e-02,\n",
       "       -1.66705981e-01, -4.43626761e-01,  1.46489471e-01,  1.73631459e-01,\n",
       "       -1.31828755e-01,  3.83885577e-02,  2.78173774e-01, -6.13845527e-01,\n",
       "        1.78056270e-01,  8.01847935e-01,  2.49036491e-01, -3.01739573e-02,\n",
       "        1.67265564e-01, -5.99431917e-02,  2.01588690e-01, -4.01664734e-01,\n",
       "        2.09002540e-01,  5.97718358e-02, -1.70693636e-01, -3.12906981e-01,\n",
       "        4.34838235e-04,  1.40490875e-01,  4.68818307e-01, -3.69145095e-01,\n",
       "        5.96957281e-02, -5.62402010e-01,  1.25702471e-02, -1.81508631e-01,\n",
       "       -3.64449799e-01,  4.31409597e-01, -5.04463911e-01,  8.24791014e-01,\n",
       "       -9.05588716e-02,  1.74931318e-01,  1.22120380e+00, -6.15253150e-02,\n",
       "        2.99329847e-01,  4.97430652e-01,  3.20654213e-01, -1.40621498e-01,\n",
       "        6.88545942e-01,  2.18970507e-01, -5.63171327e-01,  9.05827165e-01,\n",
       "        4.10800159e-01,  1.80461332e-01, -1.29953265e-01, -7.90950954e-02,\n",
       "        2.01456249e-03, -1.60126328e-01, -2.78768599e-01, -2.12674424e-01,\n",
       "       -1.39186084e-01,  3.56270611e-01, -3.45107913e-01, -2.44194999e-01,\n",
       "       -1.52955413e-01,  6.20045587e-02, -2.38332748e-01, -3.40351105e-01,\n",
       "       -1.09973371e-01, -9.03013200e-02, -2.63763517e-01,  2.40763724e-02,\n",
       "       -1.88977659e-01, -1.86788648e-01, -5.79872131e-02,  3.13950628e-01,\n",
       "        2.58456498e-01,  4.32359248e-01, -5.89179993e-01,  2.99625099e-04,\n",
       "       -3.74383539e-01,  6.16991758e-01, -2.24279121e-01, -3.84903610e-01,\n",
       "       -1.47631750e-01, -3.33579361e-01, -3.24589491e-01, -8.88826370e-01,\n",
       "       -3.82810235e-01,  5.06862521e-01,  1.54759839e-01,  4.08622622e-03,\n",
       "       -9.86389875e-01, -1.29408687e-01,  5.84792018e-01,  5.65296896e-02,\n",
       "        1.00564885e+00,  1.94329947e-01, -3.65596652e-01,  5.39217442e-02,\n",
       "       -7.65237629e-01, -6.81394339e-01,  9.62803364e-01,  4.77877259e-01,\n",
       "        1.06071793e-01, -5.29453278e-01,  2.41371647e-01,  2.00604200e-01,\n",
       "        3.77942175e-02, -5.86602986e-01,  2.93570101e-01, -3.69752914e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2 = nlp(u'man')\n",
    "token2.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9905bf99e7d480f6800465d645f831ddcc2763ab"
   },
   "source": [
    "We can use these notations and find document similarity. For example : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "7589a07b84b60e4491c6309fb43f8c5277d76010"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7366501774364348"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.similarity(token2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b498c641518b3e9c10d333afc45c0da2ce3f7748"
   },
   "source": [
    "The result states that the similarity score of the two documents is 0.76 / 1. \n",
    "\n",
    "## End Notes \n",
    "\n",
    "This notebook explains the basics of NLP techniques applied using spaCy. These techniques can be used to generate text based features, generate vector notations,  document similarity, improve topic models, imporve machine and deep learning models, and build knowledge graphs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
